{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 for Leaf Image Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "IMG_ROWS = 200\n",
    "IMG_COLS = 200\n",
    "DEPTH = 3\n",
    "DEFAULT_IMG_SIZE = tuple((IMG_ROWS, IMG_COLS))\n",
    "\n",
    "DIR = r\"C:\\Users\\chi_b\\OneDrive\\Desktop\\Machine Learning\\Leaves Classification\\QMST-5367-Machine-Learning-Plant-Image-Processing-main\\data\"\n",
    "CATEGORIES = ['poison_ivy', 'raspberry', 'tomato', 'bell_pepper', 'potato']\n",
    "\n",
    "\n",
    "#LOAD DATA\n",
    "\n",
    "data = []\n",
    "\n",
    "def import_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DIR, category)\n",
    "        num_label = CATEGORIES.index(category)\n",
    "        \n",
    "        for img_name in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_name)\n",
    "                        \n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img,DEFAULT_IMG_SIZE)\n",
    "                data.append([img, num_label])\n",
    "            except Exception:\n",
    "                pass\n",
    "                                     \n",
    "        \n",
    "        #save data file:\n",
    "        data_output= open('leaves_data.pickle', 'wb')\n",
    "        pickle.dump(data,data_output)\n",
    "        data_output.close()\n",
    "\n",
    "import_data()\n",
    "\n",
    "def load_data():\n",
    "    data_input = open('leaves_data.pickle', 'rb')\n",
    "    data = pickle.load(data_input)\n",
    "    data_input.close()\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for img, label in data:\n",
    "        features.append(img)\n",
    "        labels.append(label)\n",
    "                          \n",
    "                     \n",
    "              \n",
    "        \n",
    "    features = np.array(features).reshape(-1,IMG_ROWS,IMG_COLS, DEPTH)\n",
    "        #normalize data\n",
    "    features = features/255\n",
    "    features = features.reshape((features.shape[0],IMG_ROWS, IMG_COLS, DEPTH))\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    \n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_load_data import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "\n",
    "HEIGHT = 200\n",
    "WIDTH = 200\n",
    "DEPTH = 3\n",
    "VAL_SPLIT = 0.2\n",
    "BS = 25\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCHS = 10\n",
    "DIR = r\"C:\\Users\\chi_b\\OneDrive\\Desktop\\Machine Learning\\Leaves Classification\\QMST-5367-Machine-Learning-Plant-Image-Processing-main\"\n",
    "\n",
    "CATEGORIES = ['poison_ivy', 'raspberry', 'tomato', 'bell_pepper', 'potato']\n",
    "N_CLASSES = len(CATEGORIES)\n",
    "\n",
    "features, labels = load_data()\n",
    "\n",
    "#split data\n",
    "(x_interim, x_test, y_interim, y_test) = train_test_split(features,labels, test_size =0.2)\n",
    "\n",
    "(x_train, x_val, y_train, y_val) = train_test_split(x_interim, y_interim, test_size =0.2)\n",
    "\n",
    "\n",
    "\n",
    "#---------------- model building---------------\n",
    "def model_building():\n",
    "    checkpoint = ModelCheckpoint('weights.h5', monitor = 'val_loss', save_best_only=True)\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    callbacks_list = [checkpoint, early_stopping_monitor]\n",
    "    \n",
    "    #-------------------OPTIMIZE AND REDUCE LOSS-----------------\n",
    "    print(\"Optimizing and training network\")\n",
    "    opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\n",
    "    \n",
    "       \n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    inputShape = (WIDTH, HEIGHT, DEPTH)\n",
    "\n",
    "        \n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\",input_shape= inputShape, data_format = \"channels_last\", activation = 'relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(125, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding=\"same\", activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dense(1000, activation = 'relu'))\n",
    "       \n",
    "    model.add(Dense(N_CLASSES, activation = \"softmax\"))\n",
    "\n",
    "             \n",
    "    #-----------------Model Summary-----------------\n",
    "    model.summary()\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    #image augmentation\n",
    "\n",
    "    aug = ImageDataGenerator(\n",
    "        rotation_range=25, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, shear_range=0.2, \n",
    "        zoom_range=0.2,horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        aug.flow(x_train, y_train, batch_size=BS),\n",
    "        validation_data=(x_val, y_val),\n",
    "        steps_per_epoch=len(x_train) // BS,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, callbacks = callbacks_list\n",
    "        )\n",
    "     \n",
    "    return model,history\n",
    "\n",
    "#--------------------------EVAL MODEL-------------------\n",
    "def eval_model(model,history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    #Train and validation accuracy\n",
    "    plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "    plt.title('Training and Validation accurarcy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    #Train and validation loss\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Calculating model accuracy\")\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy: {scores[1]*100}%\")\n",
    "\n",
    "def save_model(model):\n",
    "    model.save(DIR + r\"\\project_model.h5\")\n",
    "\n",
    "def load_model():\n",
    "    import keras\n",
    "    model = keras.models.load_model(DIR + r\"\\project_model.h5\")\n",
    "    return model\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "model, history = model_building()\n",
    "\n",
    "eval_model(model, history)\n",
    "\n",
    "save_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
