{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 for Leaf Image Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages and Images & Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "HEIGHT = 150\n",
    "WIDTH = 150\n",
    "DEPTH = 3\n",
    "VAL_SPLIT = 0.2\n",
    "BS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 7\n",
    "DIR = r\"C:\\Users\\Taja\\Documents\\MSDAIS Spring 2021\\CIS 5367 Machine Learning\\Spark Projects\\data_all\"\n",
    "\n",
    "CATEGORIES = ['poison_ivy', 'raspberry', 'tomato', 'potato', 'bell pepper']\n",
    "N_CLASSES = len(CATEGORIES)\n",
    "\n",
    "features, labels = load_data()\n",
    "\n",
    "#split data\n",
    "(x_interim, x_test, y_interim, y_test) = train_test_split(features,labels, test_size =0.2)\n",
    "\n",
    "(x_train, x_val, y_train, y_val) = train_test_split(x_interim, y_interim, test_size =0.2)\n",
    "\n",
    "\n",
    "\n",
    "#---------------- model building---------------\n",
    "def model_building():\n",
    "    checkpoint = ModelCheckpoint('weights.h5', monitor = 'val_loss', save_best_only=True)\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    callbacks_list = [checkpoint, early_stopping_monitor]\n",
    "    \n",
    "    #-------------------OPTIMIZE AND REDUCE LOSS-----------------\n",
    "    print(\"Optimizing and training network\")\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "       \n",
    "    model = Sequential()\n",
    "    inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "    chanDim = -1\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (DEPTH, HEIGHT, WIDTH)\n",
    "        chanDim = 1\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(N_CLASSES))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "             \n",
    "    #-----------------Model Summary-----------------\n",
    "    #model.summary()\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    #image augmentation\n",
    "\n",
    "    aug = ImageDataGenerator(\n",
    "        rotation_range=25, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, shear_range=0.2, \n",
    "        zoom_range=0.2,horizontal_flip=True, \n",
    "        fill_mode=\"nearest\")\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "        aug.flow(x_train, y_train, batch_size=BS),\n",
    "        validation_data=(x_val, y_val),\n",
    "        steps_per_epoch=len(x_train) // BS,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1, callbacks = callbacks_list\n",
    "        )\n",
    "     \n",
    "    return model,history\n",
    "\n",
    "def eval_model(model,history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    #Train and validation accuracy\n",
    "    plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "    plt.title('Training and Validation accurarcy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    #Train and validation loss\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Calculating model accuracy\")\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy: {scores[1]*100}%\")\n",
    "\n",
    "def save_model(model):\n",
    "    model.save(DIR + r\"\\project_model.h5\")\n",
    "\n",
    "def load_model():\n",
    "    import keras\n",
    "    model = keras.models.load_model(DIR + r\"\\project_model.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model, history = model_building()\n",
    "    eval_model(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
